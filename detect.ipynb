{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para testar o modelo de YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "import os\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificação de placas de carros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image_path):    \n",
    "    model = YOLO('last.pt')  \n",
    "    results = model(image_path)\n",
    "    \n",
    "    # Display results\n",
    "    for result in results:\n",
    "        img_rgb = cv2.cvtColor(result.plot(show=False), cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "def classify_and_crop(image_path):\n",
    "    # Load model\n",
    "    model = YOLO('last.pt')\n",
    "    \n",
    "    # Run inference\n",
    "    results = model(image_path)\n",
    "    \n",
    "    # Read the original image\n",
    "    original_image = cv2.imread(image_path)\n",
    "    imgnames = []\n",
    "\n",
    "\n",
    "    # Iterate over results\n",
    "    for i, result in enumerate(results):\n",
    "        boxes = result.boxes.xyxy.cpu().numpy()  # Get bounding boxes in (x1, y1, x2, y2) format\n",
    "\n",
    "        for j, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "            # Convert coordinates to integers\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "            # Crop the image\n",
    "            cropped = original_image[y1:y2, x1:x2]\n",
    "\n",
    "            # Convert BGR to RGB for displaying\n",
    "            cropped_rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "            # Save the cropped image\n",
    "            output_filename = f'cropped_{i}_{j}.png'\n",
    "            imgnames.append(output_filename)\n",
    "            cv2.imwrite(output_filename, cropped)\n",
    "\n",
    "            # Show the cropped region\n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.imshow(cropped_rgb)\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Cropped #{i}-{j}')\n",
    "            plt.show()\n",
    "    return imgnames\n",
    "\n",
    "def classify_and_save(image_path):\n",
    "    model = YOLO('last.pt')\n",
    "    results = model(image_path)\n",
    "    \n",
    "    # Read the original image\n",
    "    original_image = cv2.imread(image_path)\n",
    "    imgnames = []\n",
    "    \n",
    "    # Iterate over results\n",
    "    for i, result in enumerate(results):\n",
    "        boxes = result.boxes.xyxy.cpu().numpy()  # Get bounding boxes in (x1, y1, x2, y2) format\n",
    "\n",
    "        for j, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "            # Convert coordinates to integers\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "            # Crop the image\n",
    "            cropped = original_image[y1:y2, x1:x2]\n",
    "\n",
    "            # Convert BGR to RGB for displaying\n",
    "            cropped_rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "            # Save the cropped image\n",
    "            output_filename = f'plates/cropped_{i}_{j}.png'\n",
    "            imgnames.append(output_filename)\n",
    "            cv2.imwrite(output_filename, cropped)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo o texto das placas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_char_in_position(word, position):\n",
    "    if position < len(word):\n",
    "        if word[position].isdigit():\n",
    "            digit = word[position]\n",
    "            if digit == '8':\n",
    "                word = word[:position] + 'B' + word[position+1:]\n",
    "            elif digit == '1':\n",
    "                word = word[:position] + 'I' + word[position+1:]\n",
    "    return word\n",
    "\n",
    "def detect_blue_strip(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return False\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "    top_strip = image[0:int(height * 0.15), 0:width]  # faixa de cima\n",
    "\n",
    "    hsv = cv2.cvtColor(top_strip, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Faixa de azul (com tolerância maior para placas borradas)\n",
    "    lower_blue = np.array([90, 40, 40])\n",
    "    upper_blue = np.array([140, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    blue_ratio = cv2.countNonZero(mask) / (top_strip.shape[0] * top_strip.shape[1])\n",
    "    return blue_ratio > 0.03\n",
    "\n",
    "\n",
    "def correct_plate(word, is_new_plate):\n",
    "    word = word.replace(\"-\", \"\")\n",
    "    if len(word) < 7:\n",
    "        return None\n",
    "\n",
    "    for pos in [0, 1, 2]:\n",
    "        if word[pos].isdigit():\n",
    "            word = change_char_in_position(word, pos)\n",
    "    \n",
    "    if is_new_plate and len(word) > 4 and word[4].isdigit():\n",
    "        word = change_char_in_position(word, 4)\n",
    "\n",
    "    # Verifica os dois formatos válidos\n",
    "    if re.match(r'^[A-Z]{3}\\d{4}$', word) or re.match(r'^[A-Z]{3}\\d[A-Z]\\d{2}$', word):\n",
    "        return word\n",
    "    return None\n",
    "\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en', show_log=False)\n",
    "\n",
    "def extract_plate_from_image(image_path):\n",
    "    is_new_plate = detect_blue_strip(image_path)\n",
    "    result = ocr.ocr(image_path, cls=True)\n",
    "    \n",
    "    if not result or result[0] is None:\n",
    "        print(\"No text detected.\")\n",
    "        return None    \n",
    "    \n",
    "    detected_words = []\n",
    "    for line in result:\n",
    "        for word_info in line:\n",
    "            text = word_info[1][0].replace(\" \", \"\")\n",
    "            if text.lower() == \"brasil\":\n",
    "                is_new_plate = True\n",
    "            else:\n",
    "                detected_words.append((text, word_info[1][1]))  # (text, confidence)\n",
    "    \n",
    "    print(f\"Palavras detectadas: {detected_words}\")\n",
    "    print(f\"É nova placa? {is_new_plate}\")    \n",
    "    \n",
    "    # Tenta cada palavra isolada\n",
    "    for word_tuple in detected_words:\n",
    "        corrected = correct_plate(word_tuple[0], is_new_plate)\n",
    "        if corrected:\n",
    "            return corrected\n",
    "\n",
    "    # Tenta pares de palavras combinadas\n",
    "    for i in range(len(detected_words)):\n",
    "        for j in range(i+1, len(detected_words)):\n",
    "            combined = detected_words[i][0] + detected_words[j][0]\n",
    "            corrected = correct_plate(combined, is_new_plate)\n",
    "            if corrected:\n",
    "                return corrected\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando com imagens reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'imgs/21.png'\n",
    "imgs = classify_and_crop(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = []\n",
    "for img in imgs:\n",
    "    print(f\"Processing image: {img}\")\n",
    "    plate = extract_plate_from_image(img)\n",
    "    print(f\"Plate detected: {plate}\")\n",
    "    if plate:\n",
    "        plates.append(plate)\n",
    "    print('-'*20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../compvis-car/Brazil/files/domain1/7471000.jpg'\n",
    "imgs = classify_and_crop(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = []\n",
    "for img in imgs:\n",
    "    print(f\"Processing image: {img}\")\n",
    "    plate = extract_plate_from_image(img)\n",
    "    print(f\"Plate detected: {plate}\")\n",
    "    if plate:\n",
    "        plates.append(plate)\n",
    "    print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.getenv('API_TOKEN', 'não-encontrado')\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = 'https://wdapi2.com.br/consulta/{placa}/{token}'\n",
    "\n",
    "placa = plates[1]\n",
    "token = os.getenv('API_TOKEN', 'default_token_value')\n",
    "response = requests.get(api_url.format(placa=placa, token=token))\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(f\"API Response: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infos(data):\n",
    "    info = {}\n",
    "    marca = data['marca']\n",
    "    modelo = data['modelo']\n",
    "    ano = data['ano']\n",
    "    cor = data['cor']\n",
    "\n",
    "    info = {\n",
    "        'marca': marca,\n",
    "        'modelo': modelo,\n",
    "        'ano': ano,\n",
    "        'cor': cor\n",
    "    }\n",
    "\n",
    "    extra = data['extra']\n",
    "\n",
    "    campos_interesse = ['municipio', 'nacionalidade', 'sub_segmento']\n",
    "    for chave in campos_interesse:\n",
    "        if chave in extra:\n",
    "            info[chave] = extra[chave]\n",
    "        else:\n",
    "            info[chave] = None\n",
    "            \n",
    "    fipe = data['fipe']['dados']\n",
    "    sum = 0\n",
    "    i = 0\n",
    "    for dados in fipe:\n",
    "        valor = dados['texto_valor']\n",
    "        valor = valor.replace(\"R$\", \"\")\n",
    "        valor = valor.replace(\".\", \"\")\n",
    "        valor = valor.replace(\",\", \".\")\n",
    "        valor = float(valor)\n",
    "        sum += valor\n",
    "        i += 1\n",
    "        \n",
    "    media = sum / i\n",
    "    info['fipe'] = media\n",
    "    \n",
    "    return info\n",
    "\n",
    "info = get_infos(data)\n",
    "print(info)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
